{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Data Lakes: Evolution of the Data Warehouse\n",
    "\n",
    "### Evolution of the Data Warehouse\n",
    "Q: Is there anything wrong with the data warehouse that we need something different?\n",
    "\n",
    "No, data warehousing is a rather **mature field** with lots of cumulative experience over the years, **tried-and-true technologies**. **Dimensional modeling is still extremely relevant** to this day.\n",
    "\n",
    "**For many organizations, a data warehouse is still the best way to go**, perhaps, the biggest change would be going from an on-premise deployment to a cloud deployment. \n",
    "\n",
    "Q: So, why do we need a data lake?\n",
    "\n",
    "In recent years, many factors drove the evolution of the data warehouse, to name a few:\n",
    "* The abundance of unstructured data (text, xml, json, logs, sensor data, images, voice, etc..)\n",
    "* Unprecedented data volumes (social, IOT, machine-generated, etc..)\n",
    "* The rise of Big Data technologies like HDFS, Spark, etc..\n",
    "* New types of data analysis gaining momentum, e.g. predictive analytics, recommender systems, graph analytics, etc..\n",
    "* Emergence of new roles like the data scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Data Lakes: Unstructured & Big Data\n",
    "\n",
    "### Abundance of Unstructured Data\n",
    "Q: Can we have unstructured data in the data warehouse?\n",
    "\n",
    "* Might be possible in the ETL process. FOr instance we might be able to distill sine elements from json data and put it in a tabular format.\n",
    "* But later, we might decide we want to transform it differently, so deciding on a particular form of transformation is a **strong commitment without enough knowledge**. E.g we start by recording # of replicas in a facebook of comments and then we interested in the frequency of angry words.\n",
    "* Some data is hard to put in a tabular format like **deep json structures**.\n",
    "* Some data like text/pdf documents could be stored as \"**blobs**\" of data in a relational database but totally **useless useless processed to extract metrics** .\n",
    "* The Hadoop file system (HDFS) made it possible to Peta Bytes of data on commodity hardware. **Much lower cost per TB** compared to MPP(Massively parallel processing) databases. \n",
    "* Associated processing tools starting from MapReduce, Pig, Hive, Impala, and Spark, to name a few, made it possible to **process this data at scale on the same hardware used for storage**.\n",
    "* It is possible to make data analysis without inserting into a predefined schema. One can load a CSV file and make a query without creating a table, inserting the data in the table. Similarly one can process unstructured text. This approach is know as \"**Schema-On-Read**\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Data Lakes: New Roles & Advanced Analytics\n",
    "* The data warehouse by design follows a **very well-architured** path yo make a **clean, consistent and performant model** that business users can easily use to gain insights and make decisions.\n",
    "* As data became an asset of highest value (**Data is the new oil**), a role like the **data scientist** started to emerge seeking value from data\n",
    "* The data scientist job is almost impossible conforming to a **single rigid representation of data**. He needs freedom to represent data, join data sets together, retrieve new external data sources and more.\n",
    "* The type of analytics such as , e.g. **machine learning, natural language processing** need to access the raw data in forms totally different from a star schema.\n",
    "\n",
    "### The Data Lake is the new Data Warehouse\n",
    "* The data lake shares the goals of the data warehouse of supporting business insights beyond the day-today transactional data handling.\n",
    "* The Data lake is new form of data warehouse that evolved to cope with:\n",
    "    * The **variety of data formats** and structuring\n",
    "    * The agile and ad-hoc nature of **data exploration** activities needed by new roles like **data scientist**\n",
    "    * THe wide data spectrum data transformation needed by **advanced analytics** like machine learning, graph analytics, and recommender systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Data Effects: Low Costs, ETL Offloading\n",
    "<img src=\"images/big_data_effects.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Data Effects: Schema-on-Read\n",
    "* Traditionally, data in a database has been much easier to process than data in plain files\n",
    "* Big Data tools in the hadoop ecosystem e.g. Hive & SPark made it easy to work with a file as easy as it is to work with a database without:\n",
    "    * ~Creating a database~\n",
    "    * ~ Inserting the data into database~\n",
    "* **Schema on-read**: as for the schema of a table (simple file on disk):\n",
    "    * It is either inferred\n",
    "    * Or specified and the data is not inserted into it, but upon read the data is checked against the specified schema\n",
    "    \n",
    "<img src=\"images/schema_on_read_1.png\">\n",
    "<img src=\"images/schema_on_read_2.png\">\n",
    "<img src=\"images/schema_on_read_3.png\">\n",
    "<img src=\"images/schema_on_read_4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Data Effects: (Un-/Semi-)Structured support\n",
    "* Spark has the ability to read/write files in:\n",
    "    * Text-based many formats, csv, josn, text\n",
    "    * Binary formats such as Avro (saves space) and Parquet (columnar)\n",
    "    * Compressed formats e.g. gzip & snappy\n",
    "    \n",
    "```python\n",
    "dfLog = spark.read.text(\"data/NASA_access_log_Jul95.gz\")\n",
    "\n",
    "dfRaw = spark.read.csv(\"data/news_worldnews.csv\")\n",
    "```\n",
    "\n",
    "* Read/write from a variety of file systems\n",
    "    * Local file system\n",
    "    * HDFS\n",
    "    * S3\n",
    "  \n",
    "  \n",
    "```python\n",
    "df = spark.read.csv(\"s3a://udacity-labs/sports/sport_league.csv\")\n",
    "```\n",
    "\n",
    "* Read/write from a variety of databases\n",
    "    * SQL through JDBC\n",
    "    * NoSQL: MongoDb, Cassandra, Neo4j, ...\n",
    "\n",
    "```python\n",
    "pgDF = spark.read.format(\"jdbc\")\\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\")\\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost\")\\\n",
    "        .option(\"dbtable\", \"public.pagila\")\\\n",
    "        .option(\"user\", \"postgresd\").option(\"password\",\"postgres\").load()\n",
    "```\n",
    "\n",
    "* All exposed in a single abstraction, the dataframe , could be processed with SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Schema on Read\n",
    "The data used in this exercise is from http://ita.ee.lbl.gov/traces/NASA_access_log_Jul95.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import  urlretrieve\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as fn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "    urlretrieve(\"ftp://ita.ee.lbl.gov/traces/NASA_access_log_Jul95.gz\",filename=\"data/NASA_access_log_Jul95.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLog = spark.read.text('data/NASA_access_log_Jul95.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick inspection of  the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see the schema\n",
    "dfLog.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1891715"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of lines\n",
    "dfLog.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|199.72.81.55 - - ...|\n",
      "|unicomp6.unicomp....|\n",
      "|199.120.110.21 - ...|\n",
      "|burger.letters.co...|\n",
      "|199.120.110.21 - ...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#what's in there? \n",
    "dfLog.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                                  |\n",
      "+-----------------------------------------------------------------------------------------------------------------------+\n",
      "|199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245                                 |\n",
      "|unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985                      |\n",
      "|199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085   |\n",
      "|burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0               |\n",
      "|199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179|\n",
      "+-----------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#a better show?\n",
    "dfLog.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                     value\n",
       "0                                   199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245\n",
       "1                        unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985\n",
       "2     199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085\n",
       "3                 burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0\n",
       "4  199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pandas to the rescue\n",
    "pd.set_option('max_colwidth', 200)\n",
    "dfLog.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let' try simple parsing with split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245</td>\n",
       "      <td>[199.72.81.55, -, -, [01/Jul/1995:00:00:01, -0400], \"GET, /history/apollo/, HTTP/1.0\", 200, 6245]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985</td>\n",
       "      <td>[unicomp6.unicomp.net, -, -, [01/Jul/1995:00:00:06, -0400], \"GET, /shuttle/countdown/, HTTP/1.0\", 200, 3985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085</td>\n",
       "      <td>[199.120.110.21, -, -, [01/Jul/1995:00:00:09, -0400], \"GET, /shuttle/missions/sts-73/mission-sts-73.html, HTTP/1.0\", 200, 4085]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0</td>\n",
       "      <td>[burger.letters.com, -, -, [01/Jul/1995:00:00:11, -0400], \"GET, /shuttle/countdown/liftoff.html, HTTP/1.0\", 304, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179</td>\n",
       "      <td>[199.120.110.21, -, -, [01/Jul/1995:00:00:11, -0400], \"GET, /shuttle/missions/sts-73/sts-73-patch-small.gif, HTTP/1.0\", 200, 4179]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0</td>\n",
       "      <td>[burger.letters.com, -, -, [01/Jul/1995:00:00:12, -0400], \"GET, /images/NASA-logosmall.gif, HTTP/1.0\", 304, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0</td>\n",
       "      <td>[burger.letters.com, -, -, [01/Jul/1995:00:00:12, -0400], \"GET, /shuttle/countdown/video/livevideo.gif, HTTP/1.0\", 200, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985</td>\n",
       "      <td>[205.212.115.106, -, -, [01/Jul/1995:00:00:12, -0400], \"GET, /shuttle/countdown/countdown.html, HTTP/1.0\", 200, 3985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>d104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985</td>\n",
       "      <td>[d104.aa.net, -, -, [01/Jul/1995:00:00:13, -0400], \"GET, /shuttle/countdown/, HTTP/1.0\", 200, 3985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074</td>\n",
       "      <td>[129.94.144.152, -, -, [01/Jul/1995:00:00:13, -0400], \"GET, /, HTTP/1.0\", 200, 7074]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                     value  \\\n",
       "0                                   199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245   \n",
       "1                        unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985   \n",
       "2     199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085   \n",
       "3                 burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0   \n",
       "4  199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179   \n",
       "5                      burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0   \n",
       "6          burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0   \n",
       "7               205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985   \n",
       "8                                 d104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985   \n",
       "9                                                129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074   \n",
       "\n",
       "                                                                                                                            tokenized  \n",
       "0                                   [199.72.81.55, -, -, [01/Jul/1995:00:00:01, -0400], \"GET, /history/apollo/, HTTP/1.0\", 200, 6245]  \n",
       "1                        [unicomp6.unicomp.net, -, -, [01/Jul/1995:00:00:06, -0400], \"GET, /shuttle/countdown/, HTTP/1.0\", 200, 3985]  \n",
       "2     [199.120.110.21, -, -, [01/Jul/1995:00:00:09, -0400], \"GET, /shuttle/missions/sts-73/mission-sts-73.html, HTTP/1.0\", 200, 4085]  \n",
       "3                 [burger.letters.com, -, -, [01/Jul/1995:00:00:11, -0400], \"GET, /shuttle/countdown/liftoff.html, HTTP/1.0\", 304, 0]  \n",
       "4  [199.120.110.21, -, -, [01/Jul/1995:00:00:11, -0400], \"GET, /shuttle/missions/sts-73/sts-73-patch-small.gif, HTTP/1.0\", 200, 4179]  \n",
       "5                      [burger.letters.com, -, -, [01/Jul/1995:00:00:12, -0400], \"GET, /images/NASA-logosmall.gif, HTTP/1.0\", 304, 0]  \n",
       "6          [burger.letters.com, -, -, [01/Jul/1995:00:00:12, -0400], \"GET, /shuttle/countdown/video/livevideo.gif, HTTP/1.0\", 200, 0]  \n",
       "7               [205.212.115.106, -, -, [01/Jul/1995:00:00:12, -0400], \"GET, /shuttle/countdown/countdown.html, HTTP/1.0\", 200, 3985]  \n",
       "8                                 [d104.aa.net, -, -, [01/Jul/1995:00:00:13, -0400], \"GET, /shuttle/countdown/, HTTP/1.0\", 200, 3985]  \n",
       "9                                                [129.94.144.152, -, -, [01/Jul/1995:00:00:13, -0400], \"GET, /, HTTP/1.0\", 200, 7074]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfArrays = dfLog.withColumn(\"tokenized\", fn.split(\"value\",\" \"))\n",
    "dfArrays.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second attempt, let's build a custom parsing UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fn.udf\n",
    "def parseUDF(line):\n",
    "    import re\n",
    "    PATTERN = '^(\\S+) (\\S+) (\\S+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(\\S+) (\\S+)\\s*(\\S*)\" (\\d{3}) (\\S+)'\n",
    "    match = re.search(PATTERN, line)\n",
    "    if match is None:\n",
    "        return (line, 0)\n",
    "    size_field = match.group(9)\n",
    "    if size_field == '-':\n",
    "        size = 0\n",
    "    else:\n",
    "        size = match.group(9)\n",
    "    return {\n",
    "        \"host\"          : match.group(1), \n",
    "        \"client_identd\" : match.group(2), \n",
    "        \"user_id\"       : match.group(3), \n",
    "        \"date_time\"     : match.group(4), \n",
    "        \"method\"        : match.group(5),\n",
    "        \"endpoint\"      : match.group(6),\n",
    "        \"protocol\"      : match.group(7),\n",
    "        \"response_code\" : int(match.group(8)),\n",
    "        \"content_size\"  : size\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245</td>\n",
       "      <td>{response_code=200, protocol=HTTP/1.0, endpoint=/history/apollo/, content_size=6245, method=GET, date_time=01/Jul/1995:00:00:01 -0400, user_id=-, host=199.72.81.55, client_identd=-}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985</td>\n",
       "      <td>{response_code=200, protocol=HTTP/1.0, endpoint=/shuttle/countdown/, content_size=3985, method=GET, date_time=01/Jul/1995:00:00:06 -0400, user_id=-, host=unicomp6.unicomp.net, client_identd=-}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085</td>\n",
       "      <td>{response_code=200, protocol=HTTP/1.0, endpoint=/shuttle/missions/sts-73/mission-sts-73.html, content_size=4085, method=GET, date_time=01/Jul/1995:00:00:09 -0400, user_id=-, host=199.120.110.21, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0</td>\n",
       "      <td>{response_code=304, protocol=HTTP/1.0, endpoint=/shuttle/countdown/liftoff.html, content_size=0, method=GET, date_time=01/Jul/1995:00:00:11 -0400, user_id=-, host=burger.letters.com, client_identd=-}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179</td>\n",
       "      <td>{response_code=200, protocol=HTTP/1.0, endpoint=/shuttle/missions/sts-73/sts-73-patch-small.gif, content_size=4179, method=GET, date_time=01/Jul/1995:00:00:11 -0400, user_id=-, host=199.120.110.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0</td>\n",
       "      <td>{response_code=304, protocol=HTTP/1.0, endpoint=/images/NASA-logosmall.gif, content_size=0, method=GET, date_time=01/Jul/1995:00:00:12 -0400, user_id=-, host=burger.letters.com, client_identd=-}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0</td>\n",
       "      <td>{response_code=200, protocol=HTTP/1.0, endpoint=/shuttle/countdown/video/livevideo.gif, content_size=0, method=GET, date_time=01/Jul/1995:00:00:12 -0400, user_id=-, host=burger.letters.com, client...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985</td>\n",
       "      <td>{response_code=200, protocol=HTTP/1.0, endpoint=/shuttle/countdown/countdown.html, content_size=3985, method=GET, date_time=01/Jul/1995:00:00:12 -0400, user_id=-, host=205.212.115.106, client_iden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>d104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985</td>\n",
       "      <td>{response_code=200, protocol=HTTP/1.0, endpoint=/shuttle/countdown/, content_size=3985, method=GET, date_time=01/Jul/1995:00:00:13 -0400, user_id=-, host=d104.aa.net, client_identd=-}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074</td>\n",
       "      <td>{response_code=200, protocol=HTTP/1.0, endpoint=/, content_size=7074, method=GET, date_time=01/Jul/1995:00:00:13 -0400, user_id=-, host=129.94.144.152, client_identd=-}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                     value  \\\n",
       "0                                   199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245   \n",
       "1                        unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985   \n",
       "2     199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085   \n",
       "3                 burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0   \n",
       "4  199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179   \n",
       "5                      burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0   \n",
       "6          burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0   \n",
       "7               205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985   \n",
       "8                                 d104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985   \n",
       "9                                                129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074   \n",
       "\n",
       "                                                                                                                                                                                                    parsed  \n",
       "0                    {response_code=200, protocol=HTTP/1.0, endpoint=/history/apollo/, content_size=6245, method=GET, date_time=01/Jul/1995:00:00:01 -0400, user_id=-, host=199.72.81.55, client_identd=-}  \n",
       "1         {response_code=200, protocol=HTTP/1.0, endpoint=/shuttle/countdown/, content_size=3985, method=GET, date_time=01/Jul/1995:00:00:06 -0400, user_id=-, host=unicomp6.unicomp.net, client_identd=-}  \n",
       "2  {response_code=200, protocol=HTTP/1.0, endpoint=/shuttle/missions/sts-73/mission-sts-73.html, content_size=4085, method=GET, date_time=01/Jul/1995:00:00:09 -0400, user_id=-, host=199.120.110.21, c...  \n",
       "3  {response_code=304, protocol=HTTP/1.0, endpoint=/shuttle/countdown/liftoff.html, content_size=0, method=GET, date_time=01/Jul/1995:00:00:11 -0400, user_id=-, host=burger.letters.com, client_identd=-}  \n",
       "4  {response_code=200, protocol=HTTP/1.0, endpoint=/shuttle/missions/sts-73/sts-73-patch-small.gif, content_size=4179, method=GET, date_time=01/Jul/1995:00:00:11 -0400, user_id=-, host=199.120.110.21...  \n",
       "5       {response_code=304, protocol=HTTP/1.0, endpoint=/images/NASA-logosmall.gif, content_size=0, method=GET, date_time=01/Jul/1995:00:00:12 -0400, user_id=-, host=burger.letters.com, client_identd=-}  \n",
       "6  {response_code=200, protocol=HTTP/1.0, endpoint=/shuttle/countdown/video/livevideo.gif, content_size=0, method=GET, date_time=01/Jul/1995:00:00:12 -0400, user_id=-, host=burger.letters.com, client...  \n",
       "7  {response_code=200, protocol=HTTP/1.0, endpoint=/shuttle/countdown/countdown.html, content_size=3985, method=GET, date_time=01/Jul/1995:00:00:12 -0400, user_id=-, host=205.212.115.106, client_iden...  \n",
       "8                  {response_code=200, protocol=HTTP/1.0, endpoint=/shuttle/countdown/, content_size=3985, method=GET, date_time=01/Jul/1995:00:00:13 -0400, user_id=-, host=d104.aa.net, client_identd=-}  \n",
       "9                                 {response_code=200, protocol=HTTP/1.0, endpoint=/, content_size=7074, method=GET, date_time=01/Jul/1995:00:00:13 -0400, user_id=-, host=129.94.144.152, client_identd=-}  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's start from the beginning\n",
    "dfParsed= dfLog.withColumn(\"parsed\", parseUDF(\"value\"))\n",
    "dfParsed.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      " |-- parsed: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfParsed.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third attempt, let's fix our UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import udf # already imported\n",
    "from pyspark.sql.types import MapType, StringType\n",
    "\n",
    "@fn.udf(MapType(StringType(),StringType()))\n",
    "def parseUDFbetter(line):\n",
    "    import re\n",
    "    PATTERN = '^(\\S+) (\\S+) (\\S+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(\\S+) (\\S+)\\s*(\\S*)\" (\\d{3}) (\\S+)'\n",
    "    match = re.search(PATTERN, line)\n",
    "    if match is None:\n",
    "        return (line, 0)\n",
    "    size_field = match.group(9)\n",
    "    if size_field == '-':\n",
    "        size = 0\n",
    "    else:\n",
    "        size = match.group(9)\n",
    "    return {\n",
    "        \"host\"          : match.group(1), \n",
    "        \"client_identd\" : match.group(2), \n",
    "        \"user_id\"       : match.group(3), \n",
    "        \"date_time\"     : match.group(4), \n",
    "        \"method\"        : match.group(5),\n",
    "        \"endpoint\"      : match.group(6),\n",
    "        \"protocol\"      : match.group(7),\n",
    "        \"response_code\" : int(match.group(8)),\n",
    "        \"content_size\"  : size\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/history/apollo/', 'content_size': '6245', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:01 -0400', 'user_id': '-', 'host': '199.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/', 'content_size': '3985', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:06 -0400', 'user_id': '-', 'host': 'uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/missions/sts-73/mission-sts-73.html', 'content_size': '4085', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:09 -0400', 'us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0</td>\n",
       "      <td>{'response_code': '304', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/liftoff.html', 'content_size': '0', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:11 -0400', 'user_id': '-', 'ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/missions/sts-73/sts-73-patch-small.gif', 'content_size': '4179', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:11 -0400', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0</td>\n",
       "      <td>{'response_code': '304', 'protocol': 'HTTP/1.0', 'endpoint': '/images/NASA-logosmall.gif', 'content_size': '0', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:12 -0400', 'user_id': '-', 'host': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/video/livevideo.gif', 'content_size': '0', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:12 -0400', 'user_id': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/countdown.html', 'content_size': '3985', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:12 -0400', 'user_id': '-'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>d104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/', 'content_size': '3985', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:13 -0400', 'user_id': '-', 'host': 'd10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/', 'content_size': '7074', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:13 -0400', 'user_id': '-', 'host': '129.94.144.152', 'cli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                     value  \\\n",
       "0                                   199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245   \n",
       "1                        unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985   \n",
       "2     199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085   \n",
       "3                 burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0   \n",
       "4  199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179   \n",
       "5                      burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0   \n",
       "6          burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0   \n",
       "7               205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985   \n",
       "8                                 d104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985   \n",
       "9                                                129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074   \n",
       "\n",
       "                                                                                                                                                                                                    parsed  \n",
       "0  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/history/apollo/', 'content_size': '6245', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:01 -0400', 'user_id': '-', 'host': '199.72...  \n",
       "1  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/', 'content_size': '3985', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:06 -0400', 'user_id': '-', 'host': 'uni...  \n",
       "2  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/missions/sts-73/mission-sts-73.html', 'content_size': '4085', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:09 -0400', 'us...  \n",
       "3  {'response_code': '304', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/liftoff.html', 'content_size': '0', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:11 -0400', 'user_id': '-', 'ho...  \n",
       "4  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/missions/sts-73/sts-73-patch-small.gif', 'content_size': '4179', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:11 -0400', ...  \n",
       "5  {'response_code': '304', 'protocol': 'HTTP/1.0', 'endpoint': '/images/NASA-logosmall.gif', 'content_size': '0', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:12 -0400', 'user_id': '-', 'host': ...  \n",
       "6  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/video/livevideo.gif', 'content_size': '0', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:12 -0400', 'user_id': '...  \n",
       "7  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/countdown.html', 'content_size': '3985', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:12 -0400', 'user_id': '-'...  \n",
       "8  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/', 'content_size': '3985', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:13 -0400', 'user_id': '-', 'host': 'd10...  \n",
       "9  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/', 'content_size': '7074', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:13 -0400', 'user_id': '-', 'host': '129.94.144.152', 'cli...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's start from the beginning\n",
    "dfParsed= dfLog.withColumn(\"parsed\", parseUDFbetter(\"value\"))\n",
    "dfParsed.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      " |-- parsed: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bingo!! we'got a column of type map with the fields parsed\n",
    "dfParsed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/history/apollo/', 'content_size': '6245', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:01 -0400', 'user_id': '-', 'host': '199.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/', 'content_size': '3985', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:06 -0400', 'user_id': '-', 'host': 'uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/missions/sts-73/mission-sts-73.html', 'content_size': '4085', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:09 -0400', 'us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>{'response_code': '304', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/liftoff.html', 'content_size': '0', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:11 -0400', 'user_id': '-', 'ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/missions/sts-73/sts-73-patch-small.gif', 'content_size': '4179', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:11 -0400', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>{'response_code': '304', 'protocol': 'HTTP/1.0', 'endpoint': '/images/NASA-logosmall.gif', 'content_size': '0', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:12 -0400', 'user_id': '-', 'host': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/video/livevideo.gif', 'content_size': '0', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:12 -0400', 'user_id': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/countdown.html', 'content_size': '3985', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:12 -0400', 'user_id': '-'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/', 'content_size': '3985', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:13 -0400', 'user_id': '-', 'host': 'd10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>{'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/', 'content_size': '7074', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:13 -0400', 'user_id': '-', 'host': '129.94.144.152', 'cli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                    parsed\n",
       "0  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/history/apollo/', 'content_size': '6245', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:01 -0400', 'user_id': '-', 'host': '199.72...\n",
       "1  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/', 'content_size': '3985', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:06 -0400', 'user_id': '-', 'host': 'uni...\n",
       "2  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/missions/sts-73/mission-sts-73.html', 'content_size': '4085', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:09 -0400', 'us...\n",
       "3  {'response_code': '304', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/liftoff.html', 'content_size': '0', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:11 -0400', 'user_id': '-', 'ho...\n",
       "4  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/missions/sts-73/sts-73-patch-small.gif', 'content_size': '4179', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:11 -0400', ...\n",
       "5  {'response_code': '304', 'protocol': 'HTTP/1.0', 'endpoint': '/images/NASA-logosmall.gif', 'content_size': '0', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:12 -0400', 'user_id': '-', 'host': ...\n",
       "6  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/video/livevideo.gif', 'content_size': '0', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:12 -0400', 'user_id': '...\n",
       "7  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/countdown.html', 'content_size': '3985', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:12 -0400', 'user_id': '-'...\n",
       "8  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/shuttle/countdown/', 'content_size': '3985', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:13 -0400', 'user_id': '-', 'host': 'd10...\n",
       "9  {'response_code': '200', 'protocol': 'HTTP/1.0', 'endpoint': '/', 'content_size': '7074', 'method': 'GET', 'date_time': '01/Jul/1995:00:00:13 -0400', 'user_id': '-', 'host': '129.94.144.152', 'cli..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfParsed.select(\"parsed\").limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                host|\n",
      "+--------------------+\n",
      "|        199.72.81.55|\n",
      "|unicomp6.unicomp.net|\n",
      "|      199.120.110.21|\n",
      "|  burger.letters.com|\n",
      "|      199.120.110.21|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfParsed.selectExpr(\"parsed['host'] as host\").limit(5).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|        parsed[host]|   parsed[date_time]|\n",
      "+--------------------+--------------------+\n",
      "|        199.72.81.55|01/Jul/1995:00:00...|\n",
      "|unicomp6.unicomp.net|01/Jul/1995:00:00...|\n",
      "|      199.120.110.21|01/Jul/1995:00:00...|\n",
      "|  burger.letters.com|01/Jul/1995:00:00...|\n",
      "|      199.120.110.21|01/Jul/1995:00:00...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfParsed.selectExpr([\"parsed['host']\", \"parsed['date_time']\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"parsed['host'] as host\",\n",
       " \"parsed['client_identd'] as client_identd\",\n",
       " \"parsed['user_id'] as user_id\",\n",
       " \"parsed['date_time'] as date_time\",\n",
       " \"parsed['method'] as method\",\n",
       " \"parsed['endpoint'] as endpoint\",\n",
       " \"parsed['protocol'] as protocol\",\n",
       " \"parsed['response_code'] as response_code\",\n",
       " \"parsed['content_size'] as content_size\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = [\"host\", \"client_identd\",\"user_id\", \"date_time\", \"method\", \"endpoint\", \"protocol\", \"response_code\", \"content_size\"]\n",
    "exprs = [ \"parsed['{}'] as {}\".format(field,field) for field in fields]\n",
    "exprs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host</th>\n",
       "      <th>client_identd</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>method</th>\n",
       "      <th>endpoint</th>\n",
       "      <th>protocol</th>\n",
       "      <th>response_code</th>\n",
       "      <th>content_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>199.72.81.55</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>01/Jul/1995:00:00:01 -0400</td>\n",
       "      <td>GET</td>\n",
       "      <td>/history/apollo/</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>6245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>unicomp6.unicomp.net</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>01/Jul/1995:00:00:06 -0400</td>\n",
       "      <td>GET</td>\n",
       "      <td>/shuttle/countdown/</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>3985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>199.120.110.21</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>01/Jul/1995:00:00:09 -0400</td>\n",
       "      <td>GET</td>\n",
       "      <td>/shuttle/missions/sts-73/mission-sts-73.html</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>4085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>burger.letters.com</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>01/Jul/1995:00:00:11 -0400</td>\n",
       "      <td>GET</td>\n",
       "      <td>/shuttle/countdown/liftoff.html</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>199.120.110.21</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>01/Jul/1995:00:00:11 -0400</td>\n",
       "      <td>GET</td>\n",
       "      <td>/shuttle/missions/sts-73/sts-73-patch-small.gif</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>4179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   host client_identd user_id                   date_time  \\\n",
       "0          199.72.81.55             -       -  01/Jul/1995:00:00:01 -0400   \n",
       "1  unicomp6.unicomp.net             -       -  01/Jul/1995:00:00:06 -0400   \n",
       "2        199.120.110.21             -       -  01/Jul/1995:00:00:09 -0400   \n",
       "3    burger.letters.com             -       -  01/Jul/1995:00:00:11 -0400   \n",
       "4        199.120.110.21             -       -  01/Jul/1995:00:00:11 -0400   \n",
       "\n",
       "  method                                         endpoint  protocol  \\\n",
       "0    GET                                 /history/apollo/  HTTP/1.0   \n",
       "1    GET                              /shuttle/countdown/  HTTP/1.0   \n",
       "2    GET     /shuttle/missions/sts-73/mission-sts-73.html  HTTP/1.0   \n",
       "3    GET                  /shuttle/countdown/liftoff.html  HTTP/1.0   \n",
       "4    GET  /shuttle/missions/sts-73/sts-73-patch-small.gif  HTTP/1.0   \n",
       "\n",
       "  response_code content_size  \n",
       "0           200         6245  \n",
       "1           200         3985  \n",
       "2           200         4085  \n",
       "3           304            0  \n",
       "4           200         4179  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfClean = dfParsed.selectExpr(*exprs)\n",
    "dfClean.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popular hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>piweba3y.prodigy.com</td>\n",
       "      <td>17572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>piweba4y.prodigy.com</td>\n",
       "      <td>11591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>piweba1y.prodigy.com</td>\n",
       "      <td>9868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>alyssa.prodigy.com</td>\n",
       "      <td>7852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>siltb10.orl.mmc.com</td>\n",
       "      <td>7573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>piweba2y.prodigy.com</td>\n",
       "      <td>5922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>edams.ksc.nasa.gov</td>\n",
       "      <td>5434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>163.206.89.4</td>\n",
       "      <td>4906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>news.ti.com</td>\n",
       "      <td>4863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>disarray.demon.co.uk</td>\n",
       "      <td>4353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   host  count\n",
       "0  piweba3y.prodigy.com  17572\n",
       "1  piweba4y.prodigy.com  11591\n",
       "2  piweba1y.prodigy.com   9868\n",
       "3    alyssa.prodigy.com   7852\n",
       "4   siltb10.orl.mmc.com   7573\n",
       "5  piweba2y.prodigy.com   5922\n",
       "6    edams.ksc.nasa.gov   5434\n",
       "7          163.206.89.4   4906\n",
       "8           news.ti.com   4863\n",
       "9  disarray.demon.co.uk   4353"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfClean.groupBy(\"host\").count().orderBy(fn.desc(\"count\")).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popular content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endpoint</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>/images/NASA-logosmall.gif</td>\n",
       "      <td>111330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>/images/KSC-logosmall.gif</td>\n",
       "      <td>89638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>/images/MOSAIC-logosmall.gif</td>\n",
       "      <td>60467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>/images/USA-logosmall.gif</td>\n",
       "      <td>60013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>/images/WORLD-logosmall.gif</td>\n",
       "      <td>59488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>/images/ksclogo-medium.gif</td>\n",
       "      <td>58801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>/images/launch-logo.gif</td>\n",
       "      <td>40871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>/shuttle/countdown/</td>\n",
       "      <td>40278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>/ksc.html</td>\n",
       "      <td>40226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>/images/ksclogosmall.gif</td>\n",
       "      <td>33585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       endpoint   count\n",
       "0    /images/NASA-logosmall.gif  111330\n",
       "1     /images/KSC-logosmall.gif   89638\n",
       "2  /images/MOSAIC-logosmall.gif   60467\n",
       "3     /images/USA-logosmall.gif   60013\n",
       "4   /images/WORLD-logosmall.gif   59488\n",
       "5    /images/ksclogo-medium.gif   58801\n",
       "6       /images/launch-logo.gif   40871\n",
       "7           /shuttle/countdown/   40278\n",
       "8                     /ksc.html   40226\n",
       "9      /images/ksclogosmall.gif   33585"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfClean.groupBy(\"endpoint\").count().orderBy(fn.desc(\"count\")).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endpoint</th>\n",
       "      <th>content_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>/images/cdrom-1-95/img0007.jpg</td>\n",
       "      <td>99981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>/shuttle/missions/sts-71/movies/sts-71-launch.mpg</td>\n",
       "      <td>999424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>/shuttle/missions/sts-71/movies/sts-71-launch.mpg</td>\n",
       "      <td>999424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>/history/apollo/apollo-13/images/index.gif</td>\n",
       "      <td>99942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>/history/apollo/apollo-13/images/index.gif</td>\n",
       "      <td>99942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>/history/apollo/apollo-13/images/index.gif</td>\n",
       "      <td>99942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>/history/apollo/apollo-13/images/index.gif</td>\n",
       "      <td>99942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>/history/apollo/apollo-13/images/index.gif</td>\n",
       "      <td>99942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>/history/apollo/apollo-13/images/index.gif</td>\n",
       "      <td>99942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>/history/apollo/apollo-13/images/index.gif</td>\n",
       "      <td>99942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            endpoint content_size\n",
       "0                     /images/cdrom-1-95/img0007.jpg        99981\n",
       "1  /shuttle/missions/sts-71/movies/sts-71-launch.mpg       999424\n",
       "2  /shuttle/missions/sts-71/movies/sts-71-launch.mpg       999424\n",
       "3         /history/apollo/apollo-13/images/index.gif        99942\n",
       "4         /history/apollo/apollo-13/images/index.gif        99942\n",
       "5         /history/apollo/apollo-13/images/index.gif        99942\n",
       "6         /history/apollo/apollo-13/images/index.gif        99942\n",
       "7         /history/apollo/apollo-13/images/index.gif        99942\n",
       "8         /history/apollo/apollo-13/images/index.gif        99942\n",
       "9         /history/apollo/apollo-13/images/index.gif        99942"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfClean.createOrReplaceTempView(\"cleanlog\")\n",
    "spark.sql(\"\"\"\n",
    "select endpoint, content_size\n",
    "from cleanlog \n",
    "order by content_size desc\n",
    "\"\"\").limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host</th>\n",
       "      <th>client_identd</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>method</th>\n",
       "      <th>endpoint</th>\n",
       "      <th>protocol</th>\n",
       "      <th>response_code</th>\n",
       "      <th>content_size</th>\n",
       "      <th>content_size_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>199.72.81.55</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>01/Jul/1995:00:00:01 -0400</td>\n",
       "      <td>GET</td>\n",
       "      <td>/history/apollo/</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>6245</td>\n",
       "      <td>6245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>unicomp6.unicomp.net</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>01/Jul/1995:00:00:06 -0400</td>\n",
       "      <td>GET</td>\n",
       "      <td>/shuttle/countdown/</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>3985</td>\n",
       "      <td>3985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>199.120.110.21</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>01/Jul/1995:00:00:09 -0400</td>\n",
       "      <td>GET</td>\n",
       "      <td>/shuttle/missions/sts-73/mission-sts-73.html</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>4085</td>\n",
       "      <td>4085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>burger.letters.com</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>01/Jul/1995:00:00:11 -0400</td>\n",
       "      <td>GET</td>\n",
       "      <td>/shuttle/countdown/liftoff.html</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>199.120.110.21</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>01/Jul/1995:00:00:11 -0400</td>\n",
       "      <td>GET</td>\n",
       "      <td>/shuttle/missions/sts-73/sts-73-patch-small.gif</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>4179</td>\n",
       "      <td>4179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   host client_identd user_id                   date_time  \\\n",
       "0          199.72.81.55             -       -  01/Jul/1995:00:00:01 -0400   \n",
       "1  unicomp6.unicomp.net             -       -  01/Jul/1995:00:00:06 -0400   \n",
       "2        199.120.110.21             -       -  01/Jul/1995:00:00:09 -0400   \n",
       "3    burger.letters.com             -       -  01/Jul/1995:00:00:11 -0400   \n",
       "4        199.120.110.21             -       -  01/Jul/1995:00:00:11 -0400   \n",
       "\n",
       "  method                                         endpoint  protocol  \\\n",
       "0    GET                                 /history/apollo/  HTTP/1.0   \n",
       "1    GET                              /shuttle/countdown/  HTTP/1.0   \n",
       "2    GET     /shuttle/missions/sts-73/mission-sts-73.html  HTTP/1.0   \n",
       "3    GET                  /shuttle/countdown/liftoff.html  HTTP/1.0   \n",
       "4    GET  /shuttle/missions/sts-73/sts-73-patch-small.gif  HTTP/1.0   \n",
       "\n",
       "  response_code content_size  content_size_bytes  \n",
       "0           200         6245                6245  \n",
       "1           200         3985                3985  \n",
       "2           200         4085                4085  \n",
       "3           304            0                   0  \n",
       "4           200         4179                4179  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCleanTyped = dfClean.withColumn(\"content_size_bytes\", fn.expr(\"cast(content_size  as int)\"))\n",
    "dfCleanTyped.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endpoint</th>\n",
       "      <th>content_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>/shuttle/countdown/video/livevideo.jpeg</td>\n",
       "      <td>6823936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>/statistics/1995/bkup/Mar95_full.html</td>\n",
       "      <td>3155499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>/statistics/1995/bkup/Mar95_full.html</td>\n",
       "      <td>3155499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>/statistics/1995/bkup/Mar95_full.html</td>\n",
       "      <td>3155499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>/statistics/1995/bkup/Mar95_full.html</td>\n",
       "      <td>3155499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>/statistics/1995/bkup/Mar95_full.html</td>\n",
       "      <td>3155499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>/statistics/1995/bkup/Mar95_full.html</td>\n",
       "      <td>3155499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>/statistics/1995/bkup/Mar95_full.html</td>\n",
       "      <td>3155499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>/statistics/1995/Jun/Jun95_reverse_domains.html</td>\n",
       "      <td>2973350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>/statistics/1995/Jun/Jun95_reverse_domains.html</td>\n",
       "      <td>2973350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          endpoint content_size\n",
       "0          /shuttle/countdown/video/livevideo.jpeg      6823936\n",
       "1            /statistics/1995/bkup/Mar95_full.html      3155499\n",
       "2            /statistics/1995/bkup/Mar95_full.html      3155499\n",
       "3            /statistics/1995/bkup/Mar95_full.html      3155499\n",
       "4            /statistics/1995/bkup/Mar95_full.html      3155499\n",
       "5            /statistics/1995/bkup/Mar95_full.html      3155499\n",
       "6            /statistics/1995/bkup/Mar95_full.html      3155499\n",
       "7            /statistics/1995/bkup/Mar95_full.html      3155499\n",
       "8  /statistics/1995/Jun/Jun95_reverse_domains.html      2973350\n",
       "9  /statistics/1995/Jun/Jun95_reverse_domains.html      2973350"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCleanTyped.createOrReplaceTempView(\"cleantypedlog\")\n",
    "spark.sql(\"\"\"\n",
    "select endpoint, content_size\n",
    "from cleantypedlog \n",
    "order by content_size_bytes desc\n",
    "\"\"\").limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host</th>\n",
       "      <th>client_identd</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>method</th>\n",
       "      <th>endpoint</th>\n",
       "      <th>protocol</th>\n",
       "      <th>response_code</th>\n",
       "      <th>content_size</th>\n",
       "      <th>content_size_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>199.72.81.55</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1995-07-01 05:00:01</td>\n",
       "      <td>GET</td>\n",
       "      <td>/history/apollo/</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>6245</td>\n",
       "      <td>6245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>unicomp6.unicomp.net</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1995-07-01 05:00:06</td>\n",
       "      <td>GET</td>\n",
       "      <td>/shuttle/countdown/</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>3985</td>\n",
       "      <td>3985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>199.120.110.21</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1995-07-01 05:00:09</td>\n",
       "      <td>GET</td>\n",
       "      <td>/shuttle/missions/sts-73/mission-sts-73.html</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>4085</td>\n",
       "      <td>4085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>burger.letters.com</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1995-07-01 05:00:11</td>\n",
       "      <td>GET</td>\n",
       "      <td>/shuttle/countdown/liftoff.html</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>199.120.110.21</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1995-07-01 05:00:11</td>\n",
       "      <td>GET</td>\n",
       "      <td>/shuttle/missions/sts-73/sts-73-patch-small.gif</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>4179</td>\n",
       "      <td>4179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   host client_identd user_id           date_time method  \\\n",
       "0          199.72.81.55             -       - 1995-07-01 05:00:01    GET   \n",
       "1  unicomp6.unicomp.net             -       - 1995-07-01 05:00:06    GET   \n",
       "2        199.120.110.21             -       - 1995-07-01 05:00:09    GET   \n",
       "3    burger.letters.com             -       - 1995-07-01 05:00:11    GET   \n",
       "4        199.120.110.21             -       - 1995-07-01 05:00:11    GET   \n",
       "\n",
       "                                          endpoint  protocol response_code  \\\n",
       "0                                 /history/apollo/  HTTP/1.0           200   \n",
       "1                              /shuttle/countdown/  HTTP/1.0           200   \n",
       "2     /shuttle/missions/sts-73/mission-sts-73.html  HTTP/1.0           200   \n",
       "3                  /shuttle/countdown/liftoff.html  HTTP/1.0           304   \n",
       "4  /shuttle/missions/sts-73/sts-73-patch-small.gif  HTTP/1.0           200   \n",
       "\n",
       "  content_size  content_size_bytes  \n",
       "0         6245                6245  \n",
       "1         3985                3985  \n",
       "2         4085                4085  \n",
       "3            0                   0  \n",
       "4         4179                4179  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCleanTypedDate = dfCleanTyped.withColumn('date_time',\n",
    "                                            fn.from_unixtime(\n",
    "                                                fn.unix_timestamp('date_time',\n",
    "                                                                  'dd/MMM/yyyy:HH:mm:ssZ')\n",
    "                                            ).cast('TIMESTAMP'))\n",
    "dfCleanTypedDate.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- host: string (nullable = true)\n",
      " |-- client_identd: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- date_time: timestamp (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- endpoint: string (nullable = true)\n",
      " |-- protocol: string (nullable = true)\n",
      " |-- response_code: string (nullable = true)\n",
      " |-- content_size: string (nullable = true)\n",
      " |-- content_size_bytes: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCleanTypedDate.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Advanced Analytics NLP\n",
    "<span style=\"color:red;font-size:1.5em;\">Note: Restart the kernel before running the following blocks</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spark-nlp==1.7.3 in c:\\users\\naqee\\anaconda3\\lib\\site-packages (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install spark-nlp==1.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a spark context that includes a 3rd party jar for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-HLMKHI3J:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x17ed9516e08>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#jarPath = \"spark-nlp-assembly-1.7.3.jar\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.jars.packages\", \"JohnSnowLabs:spark-nlp:1.8.2\") \\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read multiple files in a dir as one Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "root\n",
      " |-- data: struct (nullable = true)\n",
      " |    |-- approved_at_utc: string (nullable = true)\n",
      " |    |-- approved_by: string (nullable = true)\n",
      " |    |-- archived: boolean (nullable = true)\n",
      " |    |-- author: string (nullable = true)\n",
      " |    |-- author_flair_background_color: string (nullable = true)\n",
      " |    |-- author_flair_css_class: string (nullable = true)\n",
      " |    |-- author_flair_richtext: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- author_flair_template_id: string (nullable = true)\n",
      " |    |-- author_flair_text: string (nullable = true)\n",
      " |    |-- author_flair_text_color: string (nullable = true)\n",
      " |    |-- author_flair_type: string (nullable = true)\n",
      " |    |-- author_fullname: string (nullable = true)\n",
      " |    |-- author_patreon_flair: boolean (nullable = true)\n",
      " |    |-- banned_at_utc: string (nullable = true)\n",
      " |    |-- banned_by: string (nullable = true)\n",
      " |    |-- can_gild: boolean (nullable = true)\n",
      " |    |-- can_mod_post: boolean (nullable = true)\n",
      " |    |-- category: string (nullable = true)\n",
      " |    |-- clicked: boolean (nullable = true)\n",
      " |    |-- content_categories: string (nullable = true)\n",
      " |    |-- contest_mode: boolean (nullable = true)\n",
      " |    |-- created: double (nullable = true)\n",
      " |    |-- created_utc: double (nullable = true)\n",
      " |    |-- crosspost_parent: string (nullable = true)\n",
      " |    |-- crosspost_parent_list: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- approved_at_utc: string (nullable = true)\n",
      " |    |    |    |-- approved_by: string (nullable = true)\n",
      " |    |    |    |-- archived: boolean (nullable = true)\n",
      " |    |    |    |-- author: string (nullable = true)\n",
      " |    |    |    |-- author_flair_background_color: string (nullable = true)\n",
      " |    |    |    |-- author_flair_css_class: string (nullable = true)\n",
      " |    |    |    |-- author_flair_richtext: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- author_flair_template_id: string (nullable = true)\n",
      " |    |    |    |-- author_flair_text: string (nullable = true)\n",
      " |    |    |    |-- author_flair_text_color: string (nullable = true)\n",
      " |    |    |    |-- author_flair_type: string (nullable = true)\n",
      " |    |    |    |-- author_fullname: string (nullable = true)\n",
      " |    |    |    |-- author_patreon_flair: boolean (nullable = true)\n",
      " |    |    |    |-- banned_at_utc: string (nullable = true)\n",
      " |    |    |    |-- banned_by: string (nullable = true)\n",
      " |    |    |    |-- can_gild: boolean (nullable = true)\n",
      " |    |    |    |-- can_mod_post: boolean (nullable = true)\n",
      " |    |    |    |-- category: string (nullable = true)\n",
      " |    |    |    |-- clicked: boolean (nullable = true)\n",
      " |    |    |    |-- content_categories: string (nullable = true)\n",
      " |    |    |    |-- contest_mode: boolean (nullable = true)\n",
      " |    |    |    |-- created: double (nullable = true)\n",
      " |    |    |    |-- created_utc: double (nullable = true)\n",
      " |    |    |    |-- distinguished: string (nullable = true)\n",
      " |    |    |    |-- domain: string (nullable = true)\n",
      " |    |    |    |-- downs: long (nullable = true)\n",
      " |    |    |    |-- edited: boolean (nullable = true)\n",
      " |    |    |    |-- gilded: long (nullable = true)\n",
      " |    |    |    |-- gildings: struct (nullable = true)\n",
      " |    |    |    |    |-- gid_1: long (nullable = true)\n",
      " |    |    |    |    |-- gid_2: long (nullable = true)\n",
      " |    |    |    |    |-- gid_3: long (nullable = true)\n",
      " |    |    |    |-- hidden: boolean (nullable = true)\n",
      " |    |    |    |-- hide_score: boolean (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- is_crosspostable: boolean (nullable = true)\n",
      " |    |    |    |-- is_meta: boolean (nullable = true)\n",
      " |    |    |    |-- is_original_content: boolean (nullable = true)\n",
      " |    |    |    |-- is_reddit_media_domain: boolean (nullable = true)\n",
      " |    |    |    |-- is_robot_indexable: boolean (nullable = true)\n",
      " |    |    |    |-- is_self: boolean (nullable = true)\n",
      " |    |    |    |-- is_video: boolean (nullable = true)\n",
      " |    |    |    |-- likes: string (nullable = true)\n",
      " |    |    |    |-- link_flair_background_color: string (nullable = true)\n",
      " |    |    |    |-- link_flair_css_class: string (nullable = true)\n",
      " |    |    |    |-- link_flair_richtext: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- link_flair_template_id: string (nullable = true)\n",
      " |    |    |    |-- link_flair_text: string (nullable = true)\n",
      " |    |    |    |-- link_flair_text_color: string (nullable = true)\n",
      " |    |    |    |-- link_flair_type: string (nullable = true)\n",
      " |    |    |    |-- locked: boolean (nullable = true)\n",
      " |    |    |    |-- media: string (nullable = true)\n",
      " |    |    |    |-- media_only: boolean (nullable = true)\n",
      " |    |    |    |-- mod_note: string (nullable = true)\n",
      " |    |    |    |-- mod_reason_by: string (nullable = true)\n",
      " |    |    |    |-- mod_reason_title: string (nullable = true)\n",
      " |    |    |    |-- mod_reports: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- no_follow: boolean (nullable = true)\n",
      " |    |    |    |-- num_comments: long (nullable = true)\n",
      " |    |    |    |-- num_crossposts: long (nullable = true)\n",
      " |    |    |    |-- num_reports: string (nullable = true)\n",
      " |    |    |    |-- over_18: boolean (nullable = true)\n",
      " |    |    |    |-- parent_whitelist_status: string (nullable = true)\n",
      " |    |    |    |-- permalink: string (nullable = true)\n",
      " |    |    |    |-- pinned: boolean (nullable = true)\n",
      " |    |    |    |-- pwls: long (nullable = true)\n",
      " |    |    |    |-- quarantine: boolean (nullable = true)\n",
      " |    |    |    |-- removal_reason: string (nullable = true)\n",
      " |    |    |    |-- report_reasons: string (nullable = true)\n",
      " |    |    |    |-- saved: boolean (nullable = true)\n",
      " |    |    |    |-- score: long (nullable = true)\n",
      " |    |    |    |-- secure_media: string (nullable = true)\n",
      " |    |    |    |-- selftext: string (nullable = true)\n",
      " |    |    |    |-- selftext_html: string (nullable = true)\n",
      " |    |    |    |-- send_replies: boolean (nullable = true)\n",
      " |    |    |    |-- spoiler: boolean (nullable = true)\n",
      " |    |    |    |-- stickied: boolean (nullable = true)\n",
      " |    |    |    |-- subreddit: string (nullable = true)\n",
      " |    |    |    |-- subreddit_id: string (nullable = true)\n",
      " |    |    |    |-- subreddit_name_prefixed: string (nullable = true)\n",
      " |    |    |    |-- subreddit_subscribers: long (nullable = true)\n",
      " |    |    |    |-- subreddit_type: string (nullable = true)\n",
      " |    |    |    |-- suggested_sort: string (nullable = true)\n",
      " |    |    |    |-- thumbnail: string (nullable = true)\n",
      " |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |-- ups: long (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- user_reports: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- view_count: string (nullable = true)\n",
      " |    |    |    |-- visited: boolean (nullable = true)\n",
      " |    |    |    |-- whitelist_status: string (nullable = true)\n",
      " |    |    |    |-- wls: long (nullable = true)\n",
      " |    |-- distinguished: string (nullable = true)\n",
      " |    |-- domain: string (nullable = true)\n",
      " |    |-- downs: long (nullable = true)\n",
      " |    |-- edited: boolean (nullable = true)\n",
      " |    |-- gilded: long (nullable = true)\n",
      " |    |-- gildings: struct (nullable = true)\n",
      " |    |    |-- gid_1: long (nullable = true)\n",
      " |    |    |-- gid_2: long (nullable = true)\n",
      " |    |    |-- gid_3: long (nullable = true)\n",
      " |    |-- hidden: boolean (nullable = true)\n",
      " |    |-- hide_score: boolean (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- is_crosspostable: boolean (nullable = true)\n",
      " |    |-- is_meta: boolean (nullable = true)\n",
      " |    |-- is_original_content: boolean (nullable = true)\n",
      " |    |-- is_reddit_media_domain: boolean (nullable = true)\n",
      " |    |-- is_robot_indexable: boolean (nullable = true)\n",
      " |    |-- is_self: boolean (nullable = true)\n",
      " |    |-- is_video: boolean (nullable = true)\n",
      " |    |-- likes: string (nullable = true)\n",
      " |    |-- link_flair_background_color: string (nullable = true)\n",
      " |    |-- link_flair_css_class: string (nullable = true)\n",
      " |    |-- link_flair_richtext: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- link_flair_template_id: string (nullable = true)\n",
      " |    |-- link_flair_text: string (nullable = true)\n",
      " |    |-- link_flair_text_color: string (nullable = true)\n",
      " |    |-- link_flair_type: string (nullable = true)\n",
      " |    |-- locked: boolean (nullable = true)\n",
      " |    |-- media: string (nullable = true)\n",
      " |    |-- media_only: boolean (nullable = true)\n",
      " |    |-- mod_note: string (nullable = true)\n",
      " |    |-- mod_reason_by: string (nullable = true)\n",
      " |    |-- mod_reason_title: string (nullable = true)\n",
      " |    |-- mod_reports: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- no_follow: boolean (nullable = true)\n",
      " |    |-- num_comments: long (nullable = true)\n",
      " |    |-- num_crossposts: long (nullable = true)\n",
      " |    |-- num_reports: string (nullable = true)\n",
      " |    |-- over_18: boolean (nullable = true)\n",
      " |    |-- parent_whitelist_status: string (nullable = true)\n",
      " |    |-- permalink: string (nullable = true)\n",
      " |    |-- pinned: boolean (nullable = true)\n",
      " |    |-- pwls: long (nullable = true)\n",
      " |    |-- quarantine: boolean (nullable = true)\n",
      " |    |-- removal_reason: string (nullable = true)\n",
      " |    |-- report_reasons: string (nullable = true)\n",
      " |    |-- saved: boolean (nullable = true)\n",
      " |    |-- score: long (nullable = true)\n",
      " |    |-- secure_media: string (nullable = true)\n",
      " |    |-- selftext: string (nullable = true)\n",
      " |    |-- selftext_html: string (nullable = true)\n",
      " |    |-- send_replies: boolean (nullable = true)\n",
      " |    |-- spoiler: boolean (nullable = true)\n",
      " |    |-- stickied: boolean (nullable = true)\n",
      " |    |-- subreddit: string (nullable = true)\n",
      " |    |-- subreddit_id: string (nullable = true)\n",
      " |    |-- subreddit_name_prefixed: string (nullable = true)\n",
      " |    |-- subreddit_subscribers: long (nullable = true)\n",
      " |    |-- subreddit_type: string (nullable = true)\n",
      " |    |-- suggested_sort: string (nullable = true)\n",
      " |    |-- thumbnail: string (nullable = true)\n",
      " |    |-- title: string (nullable = true)\n",
      " |    |-- ups: long (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- user_reports: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- view_count: string (nullable = true)\n",
      " |    |-- visited: boolean (nullable = true)\n",
      " |    |-- whitelist_status: string (nullable = true)\n",
      " |    |-- wls: long (nullable = true)\n",
      " |-- kind: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataPath = \"./data/reddit/*.json\"\n",
    "df = spark.read.json(dataPath)\n",
    "print(df.count())\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Struct type to query subfields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Microsoft Corp said it has discovered hacking targeting democratic institutions, think tanks, and non-profit organizations in Europe.</td>\n",
       "      <td>jaykirsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Deutsche Bank reportedly planned to extend the dates of $340 million in loans to Trump Organization to avoid a potential nightmare of chasing a sitting president for cash</td>\n",
       "      <td>canuck_burger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Iranian \"morality police\" were forced to fire warning shots when a crowd intervened to prevent them from arresting two women for not wearing a hijab. The incident occurred in Tehran's northeastern Narmak neighbourhood on Friday night, and ended with a mob tearing the door off a police vehicle.</td>\n",
       "      <td>honolulu_oahu_mod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Trump administration 'pushing Saudi nuclear deal' which could benefit company linked to Jared Kushner - Senior Trump administration officials pushed a project to share nuclear power technology with Saudi Arabia over the objections of ethics officials, according to a congressional report</td>\n",
       "      <td>madam1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NASA Happily Reports the Earth is Greener, With More Trees Than 20 Years Agoand It's Thanks to China, India</td>\n",
       "      <td>purplexxx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                    title  \\\n",
       "0                                                                                                                                                                   Microsoft Corp said it has discovered hacking targeting democratic institutions, think tanks, and non-profit organizations in Europe.   \n",
       "1                                                                                                                              Deutsche Bank reportedly planned to extend the dates of $340 million in loans to Trump Organization to avoid a potential nightmare of chasing a sitting president for cash   \n",
       "2  Iranian \"morality police\" were forced to fire warning shots when a crowd intervened to prevent them from arresting two women for not wearing a hijab. The incident occurred in Tehran's northeastern Narmak neighbourhood on Friday night, and ended with a mob tearing the door off a police vehicle.   \n",
       "3         Trump administration 'pushing Saudi nuclear deal' which could benefit company linked to Jared Kushner - Senior Trump administration officials pushed a project to share nuclear power technology with Saudi Arabia over the objections of ethics officials, according to a congressional report   \n",
       "4                                                                                                                                                                                            NASA Happily Reports the Earth is Greener, With More Trees Than 20 Years Agoand It's Thanks to China, India   \n",
       "\n",
       "              author  \n",
       "0          jaykirsch  \n",
       "1      canuck_burger  \n",
       "2  honolulu_oahu_mod  \n",
       "3             madam1  \n",
       "4          purplexxx  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = \"data.title\"\n",
    "author = \"data.author\"\n",
    "dfAuthorTilte = df.select(title, author)\n",
    "dfAuthorTilte.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to implement the equivalent of flatMap in dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>to</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>of</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>in</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>for</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>and</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>from</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>on</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>with</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  count\n",
       "0    to     58\n",
       "1   the     46\n",
       "2    of     42\n",
       "3    in     41\n",
       "4     a     25\n",
       "5   for     20\n",
       "6   and     19\n",
       "7  from     12\n",
       "8    on     11\n",
       "9  with     10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "dfWordCount = df.select(F.explode(F.split(title,\"\\\\s+\")).alias(\"word\")).groupBy(\"word\").count().orderBy(F.desc(\"count\"))\n",
    "dfWordCount.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use an NLP libary to do Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- document: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- token: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- normal: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- lemma: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- pos: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from com.johnsnowlabs.nlp.pretrained.pipeline.en import BasicPipeline as bp\n",
    "\n",
    "dfAnnotated = bp.annotate(dfAuthorTilte, \"title\")\n",
    "dfAnnotated.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Map type to query subfields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Microsoft Corp said it has discovered hacking targeting democratic institutions, think tanks, and non-profit organizations in Europe.</td>\n",
       "      <td>[{'word': 'Microsoft'}, {'word': 'Corp'}, {'word': 'said'}, {'word': 'it'}, {'word': 'has'}, {'word': 'discovered'}, {'word': 'hacking'}, {'word': 'targeting'}, {'word': 'democratic'}, {'word': 'institutions'}, {'word': 'think'}, {'word': 'tanks'}, {'word': 'and'}, {'word': 'nonprofit'}, {'word': 'organizations'}, {'word': 'in'}, {'word': 'Europe'}]</td>\n",
       "      <td>[NNP, NNP, VBD, PRP, VBZ, VBN, VBG, VBG, JJ, NNS, VBP, NNS, CC, NN, NNS, IN, NNP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Deutsche Bank reportedly planned to extend the dates of $340 million in loans to Trump Organization to avoid a potential nightmare of chasing a sitting president for cash</td>\n",
       "      <td>[{'word': 'Deutsche'}, {'word': 'Bank'}, {'word': 'reportedly'}, {'word': 'planned'}, {'word': 'to'}, {'word': 'extend'}, {'word': 'the'}, {'word': 'dates'}, {'word': 'of'}, {'word': 'million'}, {'word': 'in'}, {'word': 'loans'}, {'word': 'to'}, {'word': 'Trump'}, {'word': 'Organization'}, {'word': 'to'}, {'word': 'avoid'}, {'word': 'a'}, {'word': 'potential'}, {'word': 'nightmare'}, {'word': 'of'}, {'word': 'chasing'}, {'word': 'a'}, {'word': 'sitting'}, {'word': 'president'}, {'word': 'for'}, {'word': 'cash'}]</td>\n",
       "      <td>[NNP, NNP, RB, VBD, TO, VB, DT, NNS, IN, CD, IN, NNS, TO, NNP, NNP, TO, VB, DT, JJ, NN, IN, VBG, DT, VBG, NN, IN, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Iranian \"morality police\" were forced to fire warning shots when a crowd intervened to prevent them from arresting two women for not wearing a hijab. The incident occurred in Tehran's northeastern Narmak neighbourhood on Friday night, and ended with a mob tearing the door off a police vehicle.</td>\n",
       "      <td>[{'word': 'Iranian'}, {'word': 'morality'}, {'word': 'police'}, {'word': 'were'}, {'word': 'forced'}, {'word': 'to'}, {'word': 'fire'}, {'word': 'warning'}, {'word': 'shots'}, {'word': 'when'}, {'word': 'a'}, {'word': 'crowd'}, {'word': 'intervened'}, {'word': 'to'}, {'word': 'prevent'}, {'word': 'them'}, {'word': 'from'}, {'word': 'arresting'}, {'word': 'two'}, {'word': 'women'}, {'word': 'for'}, {'word': 'not'}, {'word': 'wearing'}, {'word': 'a'}, {'word': 'hijab'}, {'word': 'The'}, {'word': 'incident'}, {'word': 'occurred'}, {'word': 'in'}, {'word': 'Tehran'}, {'word': 's'}, {'word': 'northeastern'}, {'word': 'Narmak'}, {'word': 'neighbourhood'}, {'word': 'on'}, {'word': 'Friday'}, {'word': 'night'}, {'word': 'and'}, {'word': 'ended'}, {'word': 'with'}, {'word': 'a'}, {'word': 'mob'...</td>\n",
       "      <td>[JJ, NN, NN, VBD, VBN, TO, VB, NN, NNS, WRB, DT, NN, VBD, TO, VB, PRP, IN, VBG, CD, NNS, IN, RB, VBG, DT, NN, DT, NN, VBD, IN, NNP, VBZ, JJ, NNP, NN, IN, NNP, NN, CC, VBD, IN, DT, NN, VBG, DT, NN, RP, DT, NN, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Trump administration 'pushing Saudi nuclear deal' which could benefit company linked to Jared Kushner - Senior Trump administration officials pushed a project to share nuclear power technology with Saudi Arabia over the objections of ethics officials, according to a congressional report</td>\n",
       "      <td>[{'word': 'Trump'}, {'word': 'administration'}, {'word': 'pushing'}, {'word': 'Saudi'}, {'word': 'nuclear'}, {'word': 'deal'}, {'word': 'which'}, {'word': 'could'}, {'word': 'benefit'}, {'word': 'company'}, {'word': 'linked'}, {'word': 'to'}, {'word': 'Jared'}, {'word': 'Kushner'}, {'word': 'Senior'}, {'word': 'Trump'}, {'word': 'administration'}, {'word': 'officials'}, {'word': 'pushed'}, {'word': 'a'}, {'word': 'project'}, {'word': 'to'}, {'word': 'share'}, {'word': 'nuclear'}, {'word': 'power'}, {'word': 'technology'}, {'word': 'with'}, {'word': 'Saudi'}, {'word': 'Arabia'}, {'word': 'over'}, {'word': 'the'}, {'word': 'objections'}, {'word': 'of'}, {'word': 'ethics'}, {'word': 'officials'}, {'word': 'according'}, {'word': 'to'}, {'word': 'a'}, {'word': 'congressional'}, {'word': 're...</td>\n",
       "      <td>[NNP, NN, VBG, NNP, NN, NN, WDT, MD, VB, NN, VBN, TO, NNP, NNP, NNP, NNP, NN, NNS, VBD, DT, NN, TO, VB, JJ, NN, NN, IN, NNP, NNP, IN, DT, NNS, IN, NNS, NNS, VBG, TO, DT, JJ, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NASA Happily Reports the Earth is Greener, With More Trees Than 20 Years Agoand It's Thanks to China, India</td>\n",
       "      <td>[{'word': 'NASA'}, {'word': 'Happily'}, {'word': 'Reports'}, {'word': 'the'}, {'word': 'Earth'}, {'word': 'is'}, {'word': 'Greener'}, {'word': 'With'}, {'word': 'More'}, {'word': 'Trees'}, {'word': 'Than'}, {'word': 'Years'}, {'word': 'Agoand'}, {'word': 'It'}, {'word': 's'}, {'word': 'Thanks'}, {'word': 'to'}, {'word': 'China'}, {'word': 'India'}]</td>\n",
       "      <td>[NNP, NNP, NNS, DT, NNP, VBZ, NNP, IN, JJR, NNP, IN, NNS, NNP, PRP, VBZ, NNS, TO, NNP, NNP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                     text  \\\n",
       "0                                                                                                                                                                   Microsoft Corp said it has discovered hacking targeting democratic institutions, think tanks, and non-profit organizations in Europe.   \n",
       "1                                                                                                                              Deutsche Bank reportedly planned to extend the dates of $340 million in loans to Trump Organization to avoid a potential nightmare of chasing a sitting president for cash   \n",
       "2  Iranian \"morality police\" were forced to fire warning shots when a crowd intervened to prevent them from arresting two women for not wearing a hijab. The incident occurred in Tehran's northeastern Narmak neighbourhood on Friday night, and ended with a mob tearing the door off a police vehicle.   \n",
       "3         Trump administration 'pushing Saudi nuclear deal' which could benefit company linked to Jared Kushner - Senior Trump administration officials pushed a project to share nuclear power technology with Saudi Arabia over the objections of ethics officials, according to a congressional report   \n",
       "4                                                                                                                                                                                            NASA Happily Reports the Earth is Greener, With More Trees Than 20 Years Agoand It's Thanks to China, India   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          metadata  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [{'word': 'Microsoft'}, {'word': 'Corp'}, {'word': 'said'}, {'word': 'it'}, {'word': 'has'}, {'word': 'discovered'}, {'word': 'hacking'}, {'word': 'targeting'}, {'word': 'democratic'}, {'word': 'institutions'}, {'word': 'think'}, {'word': 'tanks'}, {'word': 'and'}, {'word': 'nonprofit'}, {'word': 'organizations'}, {'word': 'in'}, {'word': 'Europe'}]   \n",
       "1                                                                                                                                                                                                                                                                                            [{'word': 'Deutsche'}, {'word': 'Bank'}, {'word': 'reportedly'}, {'word': 'planned'}, {'word': 'to'}, {'word': 'extend'}, {'word': 'the'}, {'word': 'dates'}, {'word': 'of'}, {'word': 'million'}, {'word': 'in'}, {'word': 'loans'}, {'word': 'to'}, {'word': 'Trump'}, {'word': 'Organization'}, {'word': 'to'}, {'word': 'avoid'}, {'word': 'a'}, {'word': 'potential'}, {'word': 'nightmare'}, {'word': 'of'}, {'word': 'chasing'}, {'word': 'a'}, {'word': 'sitting'}, {'word': 'president'}, {'word': 'for'}, {'word': 'cash'}]   \n",
       "2  [{'word': 'Iranian'}, {'word': 'morality'}, {'word': 'police'}, {'word': 'were'}, {'word': 'forced'}, {'word': 'to'}, {'word': 'fire'}, {'word': 'warning'}, {'word': 'shots'}, {'word': 'when'}, {'word': 'a'}, {'word': 'crowd'}, {'word': 'intervened'}, {'word': 'to'}, {'word': 'prevent'}, {'word': 'them'}, {'word': 'from'}, {'word': 'arresting'}, {'word': 'two'}, {'word': 'women'}, {'word': 'for'}, {'word': 'not'}, {'word': 'wearing'}, {'word': 'a'}, {'word': 'hijab'}, {'word': 'The'}, {'word': 'incident'}, {'word': 'occurred'}, {'word': 'in'}, {'word': 'Tehran'}, {'word': 's'}, {'word': 'northeastern'}, {'word': 'Narmak'}, {'word': 'neighbourhood'}, {'word': 'on'}, {'word': 'Friday'}, {'word': 'night'}, {'word': 'and'}, {'word': 'ended'}, {'word': 'with'}, {'word': 'a'}, {'word': 'mob'...   \n",
       "3  [{'word': 'Trump'}, {'word': 'administration'}, {'word': 'pushing'}, {'word': 'Saudi'}, {'word': 'nuclear'}, {'word': 'deal'}, {'word': 'which'}, {'word': 'could'}, {'word': 'benefit'}, {'word': 'company'}, {'word': 'linked'}, {'word': 'to'}, {'word': 'Jared'}, {'word': 'Kushner'}, {'word': 'Senior'}, {'word': 'Trump'}, {'word': 'administration'}, {'word': 'officials'}, {'word': 'pushed'}, {'word': 'a'}, {'word': 'project'}, {'word': 'to'}, {'word': 'share'}, {'word': 'nuclear'}, {'word': 'power'}, {'word': 'technology'}, {'word': 'with'}, {'word': 'Saudi'}, {'word': 'Arabia'}, {'word': 'over'}, {'word': 'the'}, {'word': 'objections'}, {'word': 'of'}, {'word': 'ethics'}, {'word': 'officials'}, {'word': 'according'}, {'word': 'to'}, {'word': 'a'}, {'word': 'congressional'}, {'word': 're...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [{'word': 'NASA'}, {'word': 'Happily'}, {'word': 'Reports'}, {'word': 'the'}, {'word': 'Earth'}, {'word': 'is'}, {'word': 'Greener'}, {'word': 'With'}, {'word': 'More'}, {'word': 'Trees'}, {'word': 'Than'}, {'word': 'Years'}, {'word': 'Agoand'}, {'word': 'It'}, {'word': 's'}, {'word': 'Thanks'}, {'word': 'to'}, {'word': 'China'}, {'word': 'India'}]   \n",
       "\n",
       "                                                                                                                                                                                                                 result  \n",
       "0                                                                                                                                     [NNP, NNP, VBD, PRP, VBZ, VBN, VBG, VBG, JJ, NNS, VBP, NNS, CC, NN, NNS, IN, NNP]  \n",
       "1                                                                                                 [NNP, NNP, RB, VBD, TO, VB, DT, NNS, IN, CD, IN, NNS, TO, NNP, NNP, TO, VB, DT, JJ, NN, IN, VBG, DT, VBG, NN, IN, NN]  \n",
       "2  [JJ, NN, NN, VBD, VBN, TO, VB, NN, NNS, WRB, DT, NN, VBD, TO, VB, PRP, IN, VBG, CD, NNS, IN, RB, VBG, DT, NN, DT, NN, VBD, IN, NNP, VBZ, JJ, NNP, NN, IN, NNP, NN, CC, VBD, IN, DT, NN, VBG, DT, NN, RP, DT, NN, NN]  \n",
       "3                                     [NNP, NN, VBG, NNP, NN, NN, WDT, MD, VB, NN, VBN, TO, NNP, NNP, NNP, NNP, NN, NNS, VBD, DT, NN, TO, VB, JJ, NN, NN, IN, NNP, NNP, IN, DT, NNS, IN, NNS, NNS, VBG, TO, DT, JJ, NN]  \n",
       "4                                                                                                                           [NNP, NNP, NNS, DT, NNP, VBZ, NNP, IN, JJR, NNP, IN, NNS, NNP, PRP, VBZ, NNS, TO, NNP, NNP]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPos = dfAnnotated.select(\"text\", \"pos.metadata\", \"pos.result\")\n",
    "dfPos.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pos: struct (nullable = true)\n",
      " |    |-- annotatorType: string (nullable = true)\n",
      " |    |-- begin: integer (nullable = false)\n",
      " |    |-- end: integer (nullable = false)\n",
      " |    |-- result: string (nullable = true)\n",
      " |    |-- metadata: map (nullable = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(pos, 0, 8, NNP, {'word': 'Microsoft'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(pos, 10, 13, NNP, {'word': 'Corp'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(pos, 15, 18, VBD, {'word': 'said'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(pos, 20, 21, PRP, {'word': 'it'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(pos, 23, 25, VBZ, {'word': 'has'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1624</td>\n",
       "      <td>(pos, 60, 61, IN, {'word': 'of'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>(pos, 63, 74, JJ, {'word': 'unapologetic'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1626</td>\n",
       "      <td>(pos, 76, 87, JJ, {'word': 'antisemitic'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1627</td>\n",
       "      <td>(pos, 89, 95, NNS, {'word': 'attacks'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1628</td>\n",
       "      <td>(pos, 98, 106, NN, {'word': 'vandalism'})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1629 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              pos\n",
       "0         (pos, 0, 8, NNP, {'word': 'Microsoft'})\n",
       "1            (pos, 10, 13, NNP, {'word': 'Corp'})\n",
       "2            (pos, 15, 18, VBD, {'word': 'said'})\n",
       "3              (pos, 20, 21, PRP, {'word': 'it'})\n",
       "4             (pos, 23, 25, VBZ, {'word': 'has'})\n",
       "...                                           ...\n",
       "1624            (pos, 60, 61, IN, {'word': 'of'})\n",
       "1625  (pos, 63, 74, JJ, {'word': 'unapologetic'})\n",
       "1626   (pos, 76, 87, JJ, {'word': 'antisemitic'})\n",
       "1627      (pos, 89, 95, NNS, {'word': 'attacks'})\n",
       "1628    (pos, 98, 106, NN, {'word': 'vandalism'})\n",
       "\n",
       "[1629 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPos= dfAnnotated.select(F.explode(\"pos\").alias(\"pos\"))\n",
    "dfPos.printSchema()\n",
    "dfPos.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only proper nouns NNP or NNPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(pos, 0, 8, NNP, {'word': 'Microsoft'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(pos, 10, 13, NNP, {'word': 'Corp'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(pos, 126, 131, NNP, {'word': 'Europe'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(pos, 0, 7, NNP, {'word': 'Deutsche'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(pos, 9, 12, NNP, {'word': 'Bank'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>(pos, 81, 85, NNP, {'word': 'Trump'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>(pos, 87, 98, NNP, {'word': 'Organization'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>(pos, 175, 180, NNP, {'word': 'Tehran'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>(pos, 197, 202, NNP, {'word': 'Narmak'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>(pos, 221, 226, NNP, {'word': 'Friday'})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            pos\n",
       "0       (pos, 0, 8, NNP, {'word': 'Microsoft'})\n",
       "1          (pos, 10, 13, NNP, {'word': 'Corp'})\n",
       "2      (pos, 126, 131, NNP, {'word': 'Europe'})\n",
       "3        (pos, 0, 7, NNP, {'word': 'Deutsche'})\n",
       "4           (pos, 9, 12, NNP, {'word': 'Bank'})\n",
       "5         (pos, 81, 85, NNP, {'word': 'Trump'})\n",
       "6  (pos, 87, 98, NNP, {'word': 'Organization'})\n",
       "7      (pos, 175, 180, NNP, {'word': 'Tehran'})\n",
       "8      (pos, 197, 202, NNP, {'word': 'Narmak'})\n",
       "9      (pos, 221, 226, NNP, {'word': 'Friday'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnpFilter = \"pos.result = 'NNP' or pos.result = 'NNPS' \"\n",
    "dfNNP = dfPos.where(nnpFilter)\n",
    "dfNNP.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract columns form a map in a col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Corp</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Deutsche</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Bank</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Trump</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Organization</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Tehran</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Narmak</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Friday</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  tag\n",
       "0     Microsoft  NNP\n",
       "1          Corp  NNP\n",
       "2        Europe  NNP\n",
       "3      Deutsche  NNP\n",
       "4          Bank  NNP\n",
       "5         Trump  NNP\n",
       "6  Organization  NNP\n",
       "7        Tehran  NNP\n",
       "8        Narmak  NNP\n",
       "9        Friday  NNP"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWordTag = dfNNP.selectExpr(\"pos.metadata['word'] as word\", \"pos.result as tag\")\n",
    "dfWordTag.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|    word|count|\n",
      "+--------+-----+\n",
      "|      US|   14|\n",
      "|   Trump|    9|\n",
      "|   Saudi|    8|\n",
      "|   Putin|    7|\n",
      "|  Russia|    6|\n",
      "|  Arabia|    5|\n",
      "|  Europe|    5|\n",
      "|Catholic|    4|\n",
      "|Vladimir|    4|\n",
      "|      UK|    4|\n",
      "|   China|    3|\n",
      "|   South|    3|\n",
      "|   House|    3|\n",
      "| Germany|    3|\n",
      "|    Pope|    3|\n",
      "|  Church|    3|\n",
      "|   Egypt|    3|\n",
      "|  Middle|    2|\n",
      "|     UBS|    2|\n",
      "| Mueller|    2|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "dfWordTag.groupBy(\"word\").count().orderBy(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Lake Implementation Introduction\n",
    "### The Data Lake\n",
    "* Originally, data lakes were implemented the hadoop ecosystem, namely HDFS and the various processing tools available like Hive, Pig, Impala and Spark\n",
    "* Over time the big data tools architecture and hadoop became one possible solution and not the only solution\n",
    "* We will start by the original idea and then explain the different variations to implement a data lake on AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Lake Concepts\n",
    "\n",
    "<img src=\"images/data_lake_concepts_1.png\">\n",
    "<img src=\"images/data_lake_concepts_2.png\">\n",
    "<img src=\"images/data_lake_concepts_3.png\">\n",
    "<img src=\"images/data_lake_concepts_4.png\">\n",
    "<img src=\"images/data_lake_concepts_5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Lake vs Data Warehouse\n",
    "|              | Data Warehouse| Data Lake|\n",
    "|------|---------------|----------|\n",
    "| **Data form**  | Tabular format|All formats|\n",
    "| **Data value** |High only|High-value, medium-value and to-be-discovered|\n",
    "| **Ingestion**  |ETL|ELT|\n",
    "| **Data model** |Star & snowflake with conformed dimesions or data-marts and OLAP cubes|Star, snowflakes and OLAP are also possible but other ad-hoc representations are possible|\n",
    "|   **Schema**   |Known before ingestion (schema-on-write)|On-the-fly at the time of analysis (schema-on-read)|\n",
    "| **Technology** |Expensive MPP databases with expensive disks and connectivity|Commodity hardware with parallelism as first principle|\n",
    "|**Data Quality**|High with effort for consistency and clear rules for accessibility|Mixed, some data remain in raw format, some data is transformed to higher quality|\n",
    "|   **Users**    |Business analysts|Data scientist, Business analysts & ML engineers|\n",
    "| **Analytics**  |Reports and Business Intelligence visualizations|Machine Learning, graph analytics and data exploration|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Lake options on AWS\n",
    "|Storage|Processing|AWS-Managed Solution |Vendor-Managed|\n",
    "|-------|----------|-------------------- |--------------|\n",
    "|HDFS   |Spark     |AWS EMR (HDFS + Spark|EC2 + Vendor Solution|\n",
    "|S3     |Spark      |AWS EMR (Spark Only)|EC2 + Vendor Solution|\n",
    "|S3     |Server-less|AWS Athena          |Server-less + Vendor Solution|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Options: EMR (HDFS + Spark)\n",
    "<img src=\"images/aws_emr_solution_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Options: EMR: S3 + Spark\n",
    "<img src=\"images/data_lake_option2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Options: Athena\n",
    "\n",
    "<img src=\"images/data_lake_options3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Data Lake on S3\n",
    "To complete this exercise you have to download the `credentials.csv` from AWS user.\n",
    "\n",
    "<span style=\"color:red;font-size:1.5em;\">Note: Restart the kernel before running the following blocks</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import configparser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure that your AWS credentials are loaded as env vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = pd.read_csv('credentials/credentials.csv')\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = credentials['Access key ID'][0]\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = credentials['Secret access key'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spark session with hadoop-aws package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                     .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"s3a://udacity-dend/pagila/payment/payment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|payment_id;custom...|\n",
      "|16050;269;2;7;1.9...|\n",
      "|16051;269;1;98;0....|\n",
      "|16052;269;2;678;6...|\n",
      "|16053;269;2;703;0...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer schema, fix header and separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"s3a://udacity-dend/pagila/payment/payment.csv\",sep=';', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- payment_id: integer (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- staff_id: integer (nullable = true)\n",
      " |-- rental_id: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- payment_date: string (nullable = true)\n",
      "\n",
      "+----------+-----------+--------+---------+------+--------------------+\n",
      "|payment_id|customer_id|staff_id|rental_id|amount|        payment_date|\n",
      "+----------+-----------+--------+---------+------+--------------------+\n",
      "|     16050|        269|       2|        7|  1.99|2017-01-24 21:40:...|\n",
      "|     16051|        269|       1|       98|  0.99|2017-01-25 15:16:...|\n",
      "|     16052|        269|       2|      678|  6.99|2017-01-28 21:44:...|\n",
      "|     16053|        269|       2|      703|  0.99|2017-01-29 00:58:...|\n",
      "|     16054|        269|       1|      750|  4.99|2017-01-29 08:10:...|\n",
      "+----------+-----------+--------+---------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the data yourself "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- payment_id: integer (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- staff_id: integer (nullable = true)\n",
      " |-- rental_id: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- payment_date: timestamp (nullable = true)\n",
      "\n",
      "+----------+-----------+--------+---------+------+--------------------+\n",
      "|payment_id|customer_id|staff_id|rental_id|amount|        payment_date|\n",
      "+----------+-----------+--------+---------+------+--------------------+\n",
      "|     16050|        269|       2|        7|  1.99|2017-01-24 21:40:...|\n",
      "|     16051|        269|       1|       98|  0.99|2017-01-25 15:16:...|\n",
      "|     16052|        269|       2|      678|  6.99|2017-01-28 21:44:...|\n",
      "|     16053|        269|       2|      703|  0.99|2017-01-29 00:58:...|\n",
      "|     16054|        269|       1|      750|  4.99|2017-01-29 08:10:...|\n",
      "+----------+-----------+--------+---------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "dfPayment = df.withColumn(\"payment_date\", F.to_timestamp(\"payment_date\"))\n",
    "dfPayment.printSchema()\n",
    "dfPayment.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------+---------+------+--------------------+-----+\n",
      "|payment_id|customer_id|staff_id|rental_id|amount|        payment_date|month|\n",
      "+----------+-----------+--------+---------+------+--------------------+-----+\n",
      "|     16050|        269|       2|        7|  1.99|2017-01-24 21:40:...|    1|\n",
      "|     16051|        269|       1|       98|  0.99|2017-01-25 15:16:...|    1|\n",
      "|     16052|        269|       2|      678|  6.99|2017-01-28 21:44:...|    1|\n",
      "|     16053|        269|       2|      703|  0.99|2017-01-29 00:58:...|    1|\n",
      "|     16054|        269|       1|      750|  4.99|2017-01-29 08:10:...|    1|\n",
      "+----------+-----------+--------+---------+------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfPayment = dfPayment.withColumn('month',F.month('payment_date'))\n",
    "dfPayment.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute aggregate revenue per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|month|           revenue|\n",
      "+-----+------------------+\n",
      "|    4|28327.020000003868|\n",
      "|    3|23886.560000002115|\n",
      "|    2| 9631.879999999608|\n",
      "|    1| 4824.429999999856|\n",
      "|    5| 746.6200000000017|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfPayment.createOrReplaceTempView('payment')\n",
    "spark.sql(\"\"\"\n",
    "    SELECT month, sum(amount) AS revenue\n",
    "    FROM payment\n",
    "    GROUP BY month\n",
    "    ORDER BY revenue DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as typ\n",
    "\n",
    "paymentSchema = typ.StructType([\n",
    "    typ.StructField('payment_id',typ.IntegerType()),\n",
    "    typ.StructField('customer_id',typ.IntegerType()),\n",
    "    typ.StructField('staff_id',typ.IntegerType()),\n",
    "    typ.StructField('rental_id',typ.IntegerType()),\n",
    "    typ.StructField('amount',typ.DoubleType()),\n",
    "    typ.StructField('payment_date',typ.DateType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPaymentWithSchema = spark.read.csv(\"s3a://udacity-dend/pagila/payment/payment.csv\",sep=\";\", schema=paymentSchema, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- payment_id: integer (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- staff_id: integer (nullable = true)\n",
      " |-- rental_id: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- payment_date: date (nullable = true)\n",
      "\n",
      "+----------+-----------+--------+---------+------+--------------------+\n",
      "|payment_id|customer_id|staff_id|rental_id|amount|        payment_date|\n",
      "+----------+-----------+--------+---------+------+--------------------+\n",
      "|     16050|        269|       2|        7|  1.99|2017-01-24 21:40:...|\n",
      "|     16051|        269|       1|       98|  0.99|2017-01-25 15:16:...|\n",
      "|     16052|        269|       2|      678|  6.99|2017-01-28 21:44:...|\n",
      "|     16053|        269|       2|      703|  0.99|2017-01-29 00:58:...|\n",
      "|     16054|        269|       1|      750|  4.99|2017-01-29 08:10:...|\n",
      "+----------+-----------+--------+---------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfPaymentWithSchema.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|  m|           revenue|\n",
      "+---+------------------+\n",
      "|  4|28559.460000003943|\n",
      "|  3|23886.560000002115|\n",
      "|  2| 9631.879999999608|\n",
      "|  1| 4824.429999999856|\n",
      "|  5|  514.180000000001|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfPaymentWithSchema.createOrReplaceTempView(\"payment\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT month(payment_date) as m, sum(amount) as revenue\n",
    "    FROM payment\n",
    "    GROUP by m\n",
    "    order by revenue desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Data Lake on EMR\n",
    "\n",
    "Click on the following Youtube Udacity tutorials to watch the demo on data lake on EMR: \n",
    "\n",
    "[part 1](https://www.youtube.com/watch?v=539RnL05fGQ)\n",
    "\n",
    "[part 2](https://www.youtube.com/watch?v=lr-6oUkzs2w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Data Lake on Athena\n",
    "\n",
    "Click on the following Youtube Udacity tutorials to watch the demo on data lake on EMR: \n",
    "\n",
    "[part1](https://www.youtube.com/watch?v=Cy-kJEc5oKE)\n",
    "\n",
    "[part2](https://www.youtube.com/watch?v=LWOTnS2wS9U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Lake Issues\n",
    "* Data Lake is prone to being a chaotic **data garbage dump**. Efforts are being made to put measures and practices like detailed meta-data to reduce this risk.\n",
    "* Since a major feature of the data lake is the wide accessibility of cross-department data and external data of relevance, sometimes **data governance** is not easy to implement. Telling who has access to to what is hard\n",
    "* Finally, it is still sometimes unclear, per given case, whether a data lake should **replace, offload or work in parallel** with a data warehouse or data marts. In all cases, dimensional modeling, even in the context of a data lake, continues to remain a valuable practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch EMR Cluster and Notebook\n",
    "Follow the instructions below to launch your EMR cluster and notebook.\n",
    "\n",
    "* Go to the [Amazon EMR Console](https://console.aws.amazon.com/elasticmapreduce/)\n",
    "* Select \"Clusters\" in the menu on the left, and click the \"Create cluster\" button.\n",
    "\n",
    "<img src=\"images/create-cluster-button.png\">\n",
    "\n",
    "### Step 1: Configure your cluster with the following settings:\n",
    "* Release: `emr-5.20.0` or later\n",
    "* Applications: `Spark`: Spark 2.4.0 on Hadoop 2.8.5 YARN with Ganglia 3.7.2 and Zeppelin 0.8.0\n",
    "* Instance type: `m3.xlarge`\n",
    "* Number of instance: `3`\n",
    "* EC2 key pair: `Proceed without an EC2 key pair` or feel free to use one if you'd like\n",
    "\n",
    "You can keep the remaining default setting and click \"Create cluster\" on the bottom right.\n",
    "\n",
    "<img src=\"images/configure-cluster.png\">\n",
    "\n",
    "### Step 2: Wait for Cluster \"Waiting\" Status\n",
    "Once you create the cluster, you'll see a status next to your cluster name that says Starting. Wait a short time for this status to change to Waiting before moving on to the next step.\n",
    "\n",
    "<img src=\"images/cluster-waiting.png\">\n",
    "\n",
    "### Step 3: Create Notebook\n",
    "Now that you launched your cluster successfully, let's create a notebook to run Spark on that cluster.\n",
    "\n",
    "Select \"Notebooks\" in the menu on the left, and click the \"Create notebook\" button.\n",
    "\n",
    "<img src=\"images/create-notebook-button.png\">\n",
    "\n",
    "### Step 4: Configure your notebook\n",
    "* Enter a name for your notebook\n",
    "* Select \"Choose an existing cluster\" and choose the cluster you just created\n",
    "* Use the default setting for \"AWS service role\" - this should be \"EMR_Notebooks_DefaultRole\" or \"Create default role\" if you haven't done this before.\n",
    "\n",
    "You can keep the remaining default settings and click \"Create notebook\" on the bottom right.\n",
    "\n",
    "<img src=\"images/configure-notebook.png\">\n",
    "\n",
    "### Step 5: Wait for Notebook \"Ready\" Status, Then Open\n",
    "Once you create an EMR notebook, you'll need to wait a short time before the notebook status changes from Starting or Pending to Ready. Once your notebook status is Ready, click the \"Open\" button to open the notebook.\n",
    "\n",
    "<img src=\"images/notebook-ready.png\">\n",
    "\n",
    "### Start Coding!\n",
    "Now you can run Spark code for your project in this notebook, which EMR will run on your cluster. In the next page, you'll find starter code to create a spark session and read in the full 12GB dataset for the DSND Capstone project.\n",
    "\n",
    "<img src=\"images/empty-notebook.png\">\n",
    "\n",
    "### Download Notebook\n",
    "When you are finished with your notebook, click `File` > `Download as` > `Notebook` to download it to your computer.\n",
    "\n",
    "For more information on EMR notebooks, click [here](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-managed-notebooks.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoid Paying Unexpected Costs\n",
    "\n",
    "### Pricing - Be Careful!\n",
    "From this point on, AWS will charge you for running your EMR cluster. You can find the details on the [EMR Pricing here](https://aws.amazon.com/emr/pricing/). If you run your cluster for a week with the settings specified earlier (3 instances of `m3.xlarge`), you should expect costs to be around $30.\n",
    "\n",
    "Most importantly, remember to terminate your cluster when you are done. Otherwise, your cluster might run for a day, week, month, or longer without you remembering, and youll wind up with a large bill!\n",
    "\n",
    "### Terminate Your Cluster\n",
    "\n",
    "You can terminate your cluster while still keeping the Jupyter notebook you created. In EMR, your EMR cluster and EMR notebook are decoupled (so you can reattach your notebook to a different cluster at any time)! To terminate your cluster, click \"Clusters\" in the menu on the left, check the box next to your cluster to select, and click the \"Terminate\" button.\n",
    "\n",
    "<img src=\"images/terminate-cluster.png\">\n",
    "\n",
    "### Change Cluster for Notebook\n",
    "If you still have a notebook on EMR and terminated the cluster it was connected to, you can still run that notebook at any time by creating another cluster (following the instructions in the previous section). Once you have the new cluster launched and in \"waiting\" status, click \"Notebooks\" in the menu on the left and click on the name of your notebook. Then click the \"Change cluster\" button.\n",
    "\n",
    "<img src=\"images/change-cluster-button.png\">\n",
    "\n",
    "Select your new cluster. Once your notebook reaches \"Ready\" status, you can now run this notebook on your new cluster.\n",
    "\n",
    "\n",
    "### Delete Your Notebook\n",
    "When you've finished with your project and downloaded your notebook, you can delete your notebook from EMR by selecting \"Notebooks\" in the menu on the left, selecting your notebook, and then clicking \"Delete.\" Make sure to terminate the clusters you launched for this as well.\n",
    "<img src=\"images/delete-notebook.png\">\n",
    "\n",
    "### Delete S3 buckets\n",
    "AWS charges primarily for running instances, so most of the charges will cease once you stop the cluster. However, there are smaller storage charges that continue to accrue if you don't delete your buckets. To delete your buckets, go to the [Amazon S3 console](https://console.aws.amazon.com/s3/). Choose the bucket you want to delete from the list, so that the whole bucket row is selected. Choose delete bucket, type the name of the bucket, and click \"Confirm.\"\n",
    "\n",
    "For more information about deleting folders and buckets, go to [How Do I Delete an S3 Bucket](https://docs.aws.amazon.com/AmazonS3/latest/user-guide/delete-bucket.html) in the Amazon Simple Storage Service Getting Started Guide.\n",
    "\n",
    "You can view your billing information at any time by clicking on your account name on the upper right corner of the console and go to **My Billing Dashboard**.\n",
    "\n",
    "<img src=\"images/aws-billing.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
